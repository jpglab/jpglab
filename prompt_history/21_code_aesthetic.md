# 01 The Flaws of Inheritance

You may have heard the saying prefer composition over inheritance. The advice is a little vague, so I'm going to break it down. What is composition, inheritance and why would you prefer one over the other? Both composition and inheritance are trying to solve the same problem. You have a piece of code that you're trying to reuse. Inheritance is when you have a class that contains functionality you want to reuse. So you create a subclass extending its functionality. If you simply extend a class, you've basically created a copy of the class with a new name, and then you can inject new methods to extend or override parts. We have a rudimentary image class here. It represents an RGB image and stores it as a double array of pixels. The image class hides how the image is stored in memory and provides a method for looking up pixel values. We also have some stuff we can do to the image. We have a resize method which resizes the image by a scale factor, and we have methods to flip the image horizontally or vertically. The library should support JPEG, PNG and bitmap images, but we also want to reuse all of these methods for the different types of images. So to support loading and saving these images, we add two abstract methods: save() and load(), and then we create the subclass JpgImage, PngImage and BmpImage. These subclasses implement their different versions of load() and save(), but also get all of the other methods for free. So when we load a JPEG image or PNG image we can call resize on it and then we save it. The resize method is reused for all of the image types. But when we call load or save the overriden version is called instead. This works well, but now we want to create a version of an image that doesn't come from a file at all, but instead has some methods that allow the user to draw on the image. So we create a DrawableImage class and inherit from our parent Image class. But this is where inheritance starts to have issues. The downsides of inheritance is that you've couple yourself to the parent class. The structure of the parent is thrust upon the child. We're forced to implement these to load and save methods in order to reuse our resize and flip code, even though they don't make sense for our subclass. All we can do is have these two methods throw an exception. To prevent this, we need to remove this method from our parent class and add a new parent class in between called FileImage that contains these two methods. But this also breaks anyone who currently expects the Image class to contain those methods. When new changes like this come, we're forced to edit all our classes, a very expensive refactor. This is the greatest downfall of inheritance. I find it similar to how the ideal cleanness database schema often causes problems when you scale. We've moved to NoSql databases with tons of dirty duplication. Inheritance breaks down when you need to change the code. Change is the enemy of perfect design and you often paint yourself into a corner early on with your inheritance design. This is because inheritance naturally asks you to bundle all common elements into a parent class. But the soon as you find an exception to the commonality, it requires big changes. So our alternative is to use composition. So what is composition? You've already been doing it. Composition is the pattern you're doing whenever you reuse code without inheritance. If we have two classes and they want to reuse code, they simply use the code. Let's change our image classes to be composed instead. First, we're going to remove our abstract methods from image. Now, this is no longer an abstract class. It's simply a class that represents an image in memory. In our JPEG, PNG and bitmap classes. We no longer inherit image, but we'll keep our save and load methods. They'll just now be stand alone, not overriding anything. The methods were accessing a bunch of stuff from the parent class. So what do we do about those? Well, instead of accessing them through “this” we’ll simply pass in the image in question instead. So now image represents an image and these other classes cleanly represent a specific file format. Now, if our new drawing requirement comes in, we create an image draw class that takes an image to draw to. And the methods do their thing. We're no longer bundled to the file related stuff. Because we didn't force all the common elements into a parent class we don't need to alter any of the other classes to add our ImageDraw class. Now the user no longer chooses the one class that suits their needs. They also combine classes together for their particular use case. So here we're loading a JPEG image drawing to it and then saving it. Another app could do something different, like load a bitmap image, flip it, resize it, and then save it out as a PNG. Inheritance is interesting because it actually combines two capabilities: the ability to reuse code, but also the ability to build an abstraction. Creating abstractions allow a piece of code to reuse another piece of code, but also not know which piece of code it's using. You define a contract that both sides of the abstraction agree to. This gives the code the rough shape of the other code, but it doesn't know exactly what it is. Inheritance does this by allowing a consumer to think it's taking a class, but it's actually given a subclass instead. Then the code can operate like it always does. Even if the system as a whole is doing something very different. If we go back to when our image code used inheritance, our application used the natural abstraction capability of inheritance by storing references to the parent class. When our app opens a file, we just figure out which subclass to create and then store a reference to it through the parent class. Then when the user clicks the save button, our save clicked method will get invoked and we'll just call the save method and we're abstracted from whether it's the JPEG, ping or bitmap. But with composition you don't have parent classes. You're just using the types you want. Inheritance allows you to abstract because the methods of the parent class forms a contract. A contract that says that every child class shall have at least these methods. So for our new classes without inheritance, we still want to be able to call our save and load methods without caring about which class it is. This is where interfaces come in. Instead of a full parent class with all its variables and methods, an interface simply describes the contract of what an object can do. In this case, we'll create an interface called Image File, which represents the operations an image file can do: load and save. Now, like before, we save a reference to one of our implementations. But now, through the interface and when the user click save, we call save on whatever type was created. Interfaces are a much more lightweight way to do this because our interfaces are minimal. Parent classes share everything by default, making them more difficult to change. But interfaces define only the critical parts of the contract and are easily tacked on to existing classes. Now that we have a nice abstraction for loading and saving files in our app, we can actually lift the creation of which image file out of our image app class. We’ll simply ask the user of the class to pass in the interface instead. That way this class can just focus on dealing with the UI commands and the file class can be elsewhere. There's a name for what we just did there. Dependency injection. I'll do a whole video on dependency injection, but if you've heard the term before and wondered what it was, that's it. Passing in an interface for what you're going to use. I won't say that inheritance is as evil as some would say, but I will say that I almost never use it in my code. Composition isn't perfect. You do end up with a lot of boilerplate needing to initialize all of your internal types. Many implementations will contain the same code repeated, and when you need expose information from reused code, you often need to create a lot of wrapper methods where you simply return a call to an inner type. But ultimately, composition reduces the surface area between objects, which gives you less friction as changes come in. Inheritance might be useful if you're working inside of an existing system that had highly repetitive code where you only needed to modify one thing. For example, if you had the need for 100 classes to conform to some specific interface which half of them need the same boilerplate over and over again. You might say that that means that each class has too much responsibility, and you'd be right. But changing the plugin model would cost the team months of work. You might not want to put your effort into that just yet. If you do use inheritance design the class to be inherited, I'd avoid protected variables with direct access, like we avoid making our variables public. For overriding: create an explicit protected API that you're supposed to override an access mark. Everything else is private, final or sealed. This prevents bugs when changing your parent classes because of not understanding what your child classes have done.

# 02 Abstraction can make your code worse

You have a game where you have a main character, enemy characters and obstacles. For each of these objects we need to have code that keeps track of its position in the world and code for rendering the image for each object. We could write the same code in all three classes, but you recognize that this is all similar. So instead you make a third class called Game Object that handles this for you. You now have a general implementation that tracks and renders out the object. The code is mostly identical, but you allow the subclass to specify which image is shown. You just created an abstraction. Architects have gotten really good at this game of identifying repetition and extracting it out. We get into the mode of code repetition bad, more abstraction good. But there's a hidden tradeoff that doesn't get considered: Coupling. Most engineers conceptually understand what coupling is, and they definitely feel its web when trying to modify an over coupled system. But when designing software, you don't feel the impacts of coupling. I consider coupling to be an equal and opposite reaction of abstraction. For every bit of abstraction you add, you've added more coupling. Let's explore an example. We have a program that saves out data to XML, but that's the old format. So we want to move to JSON. We could do this by adding a configuration to the save logic to support both modes. But this will make the removal of XML complicated and dangerous because they're all intermingled. So instead we'll make the JSON writer a separate class. Then we can just chop off the XML support by deleting the whole file, not needing to unweave the program logic. All right, so now we've written our fancy new JSON writing class. We might notice that both take in a file name during construction. Our little repetition detectors go off and realize that maybe. Maybe we could extract this out. So our instinct is to create a common class called file saver that just takes the file name, and our subclasses can grab it from this protected variable. But this is a bad idea. We've now coupled both of these classes to the same input. They must take a file input. So if there ever became a need to create something that didn't use a file like a database or cloud connection, this would break the abstraction. And on the flip side, this abstraction brings us no value. What does this abstraction save us? Well, I guess we don't need to assign the variable twice. But this isn't any complicated logic. It's simply assigning a variable. So for me, this squarely fits into the not worth it camp. Okay, now what about the save functionality? We could consider creating an interface that represents the “save” method, but we do know that this would increase coupling because now both of these classes are constrained to the same save method. So what benefits does this abstraction bring us? Well, let's look at the usage. We have an if statement that decides which class to create and calls save on one of them. So if we add a common interface, we only get to remove this one duplicate save line. That doesn't simplify the program in any meaningful way. So I'd also put this into the it's not worth it camp. At this point it's better to keep these as two distinct classes with no connection at all. There are two cases where it would make me decide it was worth it. One would be if we added more save options. If we had three or more we might want to extract the construction of these save objects into a separate piece of code, especially if the different savers had different parameters, like a database configuration. The other case would be if we needed our program to defer or repeat saving at a different point in the program. For example, if we wanted to save every 5 minutes automatically, we’d create a class called “IntervalSaver”, and it would make sense for this Interval Saver class to be unaware which saver it's calling. In both cases, it becomes worth it when we want to separate the decision of which saver we want from the time we actually want to save. Overall, it's good to only apply abstraction when the value it brings overweighs the coupling. This does mean that you might have a little bit of code repetition. But I think that a little code repetition brings less pain when changing code than over coupling. What do you think?

# 03 Naming things in code

The classic quote is “There are only two hard things in computer science: cache invalidation and naming things”. I do agree that these are hard to get right, but they're also easy to get wrong. And we can get 80% of the way by avoiding bad patterns. We're going to talk about what I consider to be bad naming practices, practices that if you avoid you’ll force yourself into better naming, the classic first example you'll see is you shouldn't name variables with a single letter. I suspect this originally came from when math and computer science were more or less the same. Mathematicians pride themselves on being terse. They like to crystallize down to the smallest, most concise way of expression. The thing is, you don't need to edit math, but you do need to edit code. So it's become obvious to programmers that we should avoid using single letter variable names because they don't tell you anything about the variable. But I'd argue that you should take this one step further. You should never abbreviate names, period. Look at this code. Can you tell me its purpose? What about now? Abbreviations rely on context that you may or may not have. You spend more time reading code than writing code. So forcing yourself to understand per system naming patterns makes it much harder to dig into unfamiliar code. Abbreviations used to help because of two reasons: It saved you typing and screens were 80 characters wide. But now, when we write code, we get this. It takes less keyboard strokes than ever to write variable names. And we have massive 4K screens now. So there's no real advantage to abbreviation. Don't put types in your name. If you've edited older code on Windows, you'll see something called Hungarian notation. This is where you'd prefix the type to the variable name. I think this goes back to before we had good standard types in C, so everything would basically be int and the type of the variable wouldn't actually tell you what was inside of it. But now with statically typed languages, the type should tell you exactly what you're looking at. So putting types in your variables is no longer necessary. Related, it's considered good practice to put units in your variable names. For example, if you have a function that accepts a delay time. If this value is in seconds, you should name the variable delaySeconds. This way it's clear to the user of the function that they better be putting in seconds. It's also more clear to someone editing the class itself what unit they're working with. But even better than that is to have a type that removes the ambiguity completely. For example, in C#, the time span or chrono::duration in C++. The type abstracts the user from understanding the exact underlying unit. You need to explicitly ask for a unit back. Like here, getting seconds back. For dynamically typed languages like Python, you sadly can't rely on type declarations to help. So we'll need a bit of help from the variable name. Interestingly, people also add types to their types. In C# there's this pattern of prefixing interfaces with “I”. This is something I have never understood. Good code uses interfaces all the time and the consumer doesn't really care whether it's an interface, class, or abstract class. They just want to know what they can call. In this code, we animate an object on the screen. This is an interface. If I swap this to an abstract class or a concrete class, it wouldn't change this code. Nor would it help the code do anything better. C# is still following this pattern, even for new .NET library code. So for your C# code, it might make sense just to follow the pattern. Since bad style guidelines are better than no style guidelines. For other languages, I’d definitely avoid. Another example of typing your types is if you find yourself naming a class with “Base” or “Abstract”. This I've never found in a standard library. If I have a “Truck” class and then realize that it might make sense to create a parent class instead. I've seen folks name the new parent class “BaseTruck”. This isn't a great name because it doesn't help the users of the class. It still represents a truck. If you ever find yourself unable to come up with a good name for the parent class, it probably means that we should actually rename the child class instead. Instead of “BaseTruck”, let's just name it “Truck”. And for the child class lets over specify the name. We'll call it a “TrailerTruck”. Now, if someone gets a truck, they understand what they're getting. It's a truck. And they don't need to know about any of the details of subclasses. And if they need to know a specific type of truck, well, then they get the specific name. Sometimes if you're struggling to name something, it's actually indicative that the code structure is to blame. A common anti pattern I see is if there's a collection of functions used widely in the code base, but it's all bundled up into a single utils class or module. If you're thinking of naming code “utils” or “helper”, you should think if it's really the right spot for it. Here's some code from a no doubt that processes movies. There's a bunch of util functions here. Firstly, we should consider whether some of these methods actually make sense as a part of their respective types instead. So this code here, we can actually just move into the movie class itself. For some of these, we can instead create a class that represents a collection of movies and that has the desired methods. And finally, some of these can be separated into other classes with descriptive names. The paging functionality can be moved into its own class, and we can even make this generic if we want, so that it can operate on more than just movies. And the cookie function should really just be in a cookie class. Now we don't have anything in our utils class, so we can just delete it. You don't see a bundle of utils in standard libraries because they can all be sorted into modules that have good names. So we should do the same in our code. These few rules will help you write code that is easier to read and change. What would you add?

# 04 Why you should never nest your code

I have to admit, I'm a never nester. I know. Shocking. But there are more of us than you think. Dozens. Even Linus Torvalds is one. I mean, I haven't asked him, but I'll show you what I mean in a little bit. You might be wondering, well, what is a never nester. A never nester never nests their code. Okay. Not never. But we do have a disgust-o-meter which grows uncontrollably as the number of tabs go up. Nesting code is when you add more inner blocks to a function. We’ll consider each open brace to be adding one more depth to the function. So this function is one deep because there's no inner blocks. And if we add an if statement, we've made it two deep. If we add a loop, we've now made this function three deep. And this, my fellow programmers, is the maximum a never nester can handle. A never nester doesn't dare to go four deep. Now the perverse among you might wonder what four deep even looks like. And while it brings me great pain to do, I understand that I must show you for science. Here is four deep. We've now taken a reasonably readable function and dramatically increased the amount of conditions your brain must simultaneously hold. But what can we do about it? Well, there's two methods you can use to denest: Extraction. This is where you pull out part of the function into its own function. And inversion, which is simply flipping conditions and switching to an early return. Let's look at extraction first. We can extract the inner part of the loop into its own function. Now we can apply inversion. When you put the happy path of code within deeper and deeper blocks, it creates a lot of nesting. Instead, we'll invert that condition and put the unhappy first. First, we'll flip our if else, by inverting the condition. Now, since we can return here, we know that the else block isn't actually needed so we can flatten our else into the main level. Now, if we hit our unhappy case condition here, we simply get out of the way. And then the main part of the code can do its job. When you have a lot of conditions to check like this, we can apply inversion over and over again and we end up with a sort of validation gatekeeping section of the code which sort of declares the requirements of the function. And then we have the crux of the real functionality here. And you'll notice that the happy path moves down the function and all of the error paths. They're indented. When reading this code, I find I can mentally discard the condition and focus on the core code versus when it's nested. I find myself having to hold these ideas in my head. I'm curious if you’ve experienced the same thing? Let's look at a larger example. All right. Look at this beauty. Before we go refactoring it, let me walk you through what's happening. The goal of this code is to download a bunch of files from the web. It talks with this download class that we can't alter. It's an async download. So when we start the download, you have to call process over and over again. And each time it gives you one of these results. If it returns InProgress, we'll need to keep calling process() more. On top of that, we want to download multiple files at once in the background. So we've created a thread that manages all of them. The way new downloads enter the system is through this append download method, which puts the requested URLs onto a queue. The thread then wakes up and grabs the URLs from the queue and then adds them to this list of current downloads. Each download is given a state which is either pending InProgress or Complete. So in each cycle of the main loop, the thread walks through each download and checks what it needs to do with it. If it's pending we start a new download. If it's complete, we simply remove it from the list. If it's InProgress, we call that process method we mentioned earlier and figure out what's happening with the download. If it's completed successfully, we mark it as complete so it can get removed from the list and InProgress means we do nothing because it's still ongoing. But things get interesting if we hit an error, if the connection was okay, but we got an unhappy HTTP response. We determine whether the air is retriable If it is, we retry up to three times, setting the download back to Pending. Once it's failed plenty, we ejected from our download list and push it to a failure queue for someone else to deal with. For connection error, we retry three times. Then we set the special connection disabled flag and this causes us to basically give up on every download and clear the list. Okay, so there's a lot going on here and it's all heavily nested in this function, which makes it hard to follow. So let's apply extraction and inversion to flatten the first two big candidates. Here are the two big branches of download processing: Pending and InProgress. So let's extract these out. We'll move the pending part to processPending() and InProgress to processInProgress(). That's a bit better. But this in-progress function is still too deep for my liking. The worst offender is this HTP error section. So let's move that out as well. Now we'll keep extracting further in our run function. We have four major sections of our code. Where we process incoming requests from the queue; Where we deal with our current downloads; where we clear out the InProgress downloads, and where we wait for the signal that there's new downloads to look at. So let's do it. So now our main function clearly outlines the steps that are happening. You can see the high level logic I described before. And if you were to dig into any of these functions, there are also concise. At the beginning of this video, I mentioned that Linus Torvalds is a suspected never nester. And I say this because in the Linux kernel style guidelines they state if you need more than three levels of indentation, you're screwed anyway and should fix your program. The kernel dudes are always so dramatic. They visually enforce this by making the tab size eight characters wide. This is what eight characters look like with heavy nesting. Yeah. I'll admit I'm not that committed to the cause, but I am into limiting indentation. I believe that constraining how much you nest forces you to write better code. If you notice, instead of one large function that handles many things. We now have small, concise functions that have one responsibility. What do you think?

# 05 Don't write comments

It's time to get a bit controversial. I don't think you should write comments in your code pretty much most of the time. Here, we have some code where we expect the value to be 5 Looking at this code, it's not obvious what five signals. We could add a comment explaining what five is, but even better we can create a constant representing the variable instead. The if statement now reads like a comment: that we want status to be message sent. If your code is complex enough that it warrants a comment, you should instead see if you can simplify or refactor the code to make it better instead. Right now, this condition is complex enough that we add a comment explaining it, but we can simplify this by using variables to name parts of the expression. Now the condition reads like the comment does. So the comment is basically redundant and can be removed. When conditions are complex enough like this, you could also consider moving the whole condition to its own function. Now you don't need to decipher at all. Types can also make comments redundant. In C++, there's no built in memory management. You often have a function like this where you get back a thing, but we need to make clear who will take ownership of the thing. Ownership, meaning the responsibility to release the memory after everyone is done with it. In older C++, you pretty much had to rely on comments to do this. If you were given ownership of an object, you'd find out by reading the comments of the function. But C++ added a new type called unique_ptr. The type represents a unique reference to the object. So if you get one, congratulations! It's now your responsibility. The type tells you explicitly that you now own it without the need for a comment. And even better, the type makes it so you get a compile error if you do bad things with it. A comment doesn't do that. Likewise, if we have a function that returns an int, but that int is optional. We could add a comment saying that -1 means we're not actually returning a value. But even better, we could use a type. If we return an optional int instead, it's now obvious that we might not give a value. We can't miss the comment and not realize that we might get an invalid timestamp back. The user needs to handle a missing value or they'll get a compiler error. You might wonder why don't we just make our code high quality and add comments anyways? Isn't more comments just better? That ignores the problems with comments. Comments get bugs like code. When people make changes to code, they often don't update the comments to match. But unlike comments, we have tools to stop bugs from entering code. We have tests, compiler checks and limiting. We don't have any system like that for comments. Maybe one day we can have some static analysis tool that uses AI to determine if the code matches the comments and flags any discrepancies - there's a start up idea - but because of this I don't trust the comments even when they exist. Comments can lie, but code cannot. So when trying to understand what a piece of code does, I read the code. I never read the comments. Maybe it's just me. Do you guys find yourself reading comments to understand code? What I do read is code documentation. Code documentation describes the high level architecture and public APIs of a system. Code documentation differs from comments where comments describe the internals of how your code works. Documentation describes how you use the code. The world needs more high quality documentation, and while we could write the documentation for our code completely separated from our code, it makes sense to keep our documentation as close to the code as possible in order to try to help them stay in sync. Tools like Doxygen, pydoc and JavaDoc generate documents directly from code files and therefore change alongside our code. It's useful to document what a class or API represents and any expectations for interface definitions like thread safety, possible states or error conditions. This helps the consumers of the API know how to use it and also helps any new implementers of the interface know how they're supposed to operate and behave. The guidance I've given about comments still applies for documentation. If we write better APIs, our documentation will be more concise and less prone to errors. But I concede that you'll never be able to make all of the parts of the system obvious with pure code. I do think there's a few cases where you should consider comments: if the code does something non-obvious for performance reasons, a comment can help explain why the code looks weird. If the code is utilizing a specific mathematical principle or an algorithm from a particular source you might consider linking to the source to help future maintainers. There's this comic called comic strip, and one of the comics is about a guy telling a developer that one day we won't need code in the future because you'll be able to simply write a spec and the program will just write itself. The developers are casting retorts that code is just a more precise way of writing a spec. I mean, I think it's wrong. And A.I. is coming for all our jobs, and we should be afraid of the impending sociopolitical turmoil that comes when our best tool for distributing wealth, the job disappears. But alas, it still helps my point. Code is a much better way to express intent than comments about code. So in general, if you feel like you need human language to describe your code, see if you could make your code more human. What other cases do you think comments are needed?

# 06 Premature optimization

I truly do believe that premature optimization is the root of all evil. Most conversations about performance are a total waste of time, not because performance isn’t important, but because people feel very, very strongly about performance. I tend to think of performance as an element of this tradeoff triangle. Velocity, here, is how quickly one adds new features and adaptability is how well the system can change to new requirements. You might think that velocity and adaptation go hand in hand, and they do. But sometimes one can hurt the other. Focusing on pure velocity means hacking together something as fast as possible. Taking the shortest path to the feature. Future maintainers be damned, and at the beginning you'll gain a lot of immediate velocity as you hack things together. But as you do this, you're creating a bunch of technical debt which will weigh you down to a halt. Adaptability is about writing the code in a way to enable changes as new requirements come in. Think creating reusable extensible components, beautifully crafted interfaces and configurability. With the right designs, you can increase velocity by reducing the size of changes needed to add new features. But if you make things too adaptable, you also hurt velocity. If you had a crystal ball and could see the future, you'd be able to know exactly which use cases you'd need to design for and also which ones you don't need to design for. But when you build a highly adaptable system that can adapt to a whole bunch of cases that never happen, then all of that just ends up being a big waste of time. With highly extensible systems, you also hurt performance. Adding lots of adaptability naturally adds more abstraction and indirection in your code, which usually has a negative impact on performance. But this trade off is usually worth it because of the adaptability it allows. You might think you always want something in the middle, but I actually believe this depends on the stage of your project. A feature complete game pushing final ship date would focus on performance. You might be okay with reducing the velocity of new changes and adaptability in order to squeeze out the last little bit of performance. But when a game is at earlier in development, you might focus on getting more features out quickly or building up an extensible system that lets you tweak the game freely. When Mark Zuckerberg wrote Facebook, he did it in. PHP. PHP is an awkward language, to say the least, and it gave Facebook a whole slew of scaling issues as Facebook grew. They ended up making a PHP to C++ compiler. And later, when that had a performance plateau, they basically created a dialect of PHP called Hack. But would Zuckerberg be better off if he wrote it in highly optimized code to start? No, I don't think so. I think writing in the inconsistent, inefficient PHP was the right move because it meant that he could build Facebook quickly. Once performance became a real problem Engineers went to solve it. If he focused on choosing performance over velocity, it's not clear that Facebook would have taken off and Zuckerberg wouldn't have had the privilege to visit Congress as much as he has. So the key with the triangle is that performance is a problem, but it's not usually the first problem. And you should be deliberate about which way you're leaning. It's useful to differentiate performance issues into two camps: macro performance, which I think of as design level performance - these are system wide performance considerations; and micro performance, which is fine tuned performance. This could be looking at the perf of a single module or function. Premature optimization usually occurs for micro performance. This is typically where someone comments in a code review that you should do X instead of Y because x is faster than y, but computers are really fast. I have some python code that helps me generate the code animations for this series, and that python code do some horrific stuff. Each character, my code is basically in a big array and on every frame I just linear search through it to find the relevant characters, and it still renders me out of video fast enough that it's not worth making it any faster. At the end of the day, you're writing code to solve a real world problem and typically getting to the solution of that real world problem faster is better than solving the problem slower with faster code. Let's look at a few examples of premature optimization. In C++, there's two operators that both let you increment a variable by one. Proponents of ++i. will say it's faster because technically i++ needs to make a copy of the value since when it's part of a larger expression, the incrementation needs to happen after the expression is evaluated. Oh man, this one gets me. You might say, but CodeAesthetic if it's faster. Well, then why don't you just do it? Why don't you just always do ++i? Because sir/madame. Think of the precedence. I don't know for a fact that it is indeed faster. And so should I blindly trust Daryl because he thinks it's faster? No, of course not. So now I need to go through and do a thorough and lengthy investigation into the distinction between i++ and ++i. Now, I've got to go and disassemble it. I write a for loop with the pre increment operator and look at what it does. Okay. Here it loads the value from i into a register, EAX, then adds one to it and then puts the result back into the memory for i. Okay. Seems straightforward. So let's look at post increment and it's identical. You get the same code for both. Okay. But this is just an int. What if it's an iterator? We have a vector which is just C++ versions of a list and you can access the elements of the vector through an object that overrides the two ++ operators. The post one would need to make a copy, right? Well, let's look. Aha. Gotcha. Look at the difference between these two long functions. You'll notice that this one calls the function for the post and this one calls the function for the pre. And the post version of this has four extra assembly lines to make a copy of the iterator and it calls into the other operator. So you got me. It does cost a little bit more to do i++. Except when you turn on optimization, those function calls completely disappear and you end up with identical code for both cases. So now the answer is a thorough and totally satisfying: maybe. We must measure. After measuring the difference on my MacBook the speed of the slowest increment is 3.4 nanoseconds. If you notice a little counter below, this is how many worst case increments have occurred since I started talking about this. Is my increment really going to execute this many times? Is my code going to even ship? Will my startup fail? I spent 3 hours on this investigation. Could have spent 3 hours building the best dog walking app known to humanity. Does anything really matter? So my point with this is that you should ask yourself, is this conversation even worth it? If it brings you joy to figure out which is technically faster, go for it. But I don't think this should end up on a code review because it doesn't matter. Otherwise, I have to go through this whole thing again. I like i++ because I think it looks prettier. And until someone tells me that we can't ship because our app is too slow and we've measured that the solution is to change all of our i++s to ++is, I'm sticking with it. This also applies to functions. In many of my previous videos, I've argued about using extraction to help readability. Some have argued that functions are expensive, but rarely has the cost of a function been so significant that removing the function is the solution to a performance problem. And in the rare instance that it was a solution, it doesn't mean that it's proof that it's worth the readability loss by default. A big issue with making performance rules to follow is that often the rules have a lot of exceptions. Here we have a class that keeps track of the currently logged in users. Our first implementation just has an array which contains a list of users. Then we have this loggedIn() method which returns whether or not the user's logged in. It has a simple for loop which looks through the list searching for the current user. During a code review Someone says, “Hey, this thing is slow. You shouldn't just search the list of users like that. It's slow, and you should use a set instead” - a data structure that lets you look up unique elements much faster. But when you measure the difference, you actually find that set is slower when you only have a few users log in, which is normal for your system. I’d speculate this is because our integers in the area right beside each other in memory and the implementation of set likely allocates objects in lots of different places in memory - reducing cache hits. But like I said before, until you've shown that this function specifically is the leading cause of your performance issues, go with what's more readable. So I do think that set creates cleaner, more readable and less bug prone code. So I'd go with that. There's so many factors to performance that there's only one way to properly optimize: measure., try something, measure again. Measuring is critical because like we just showed your assumptions of what will make things faster, can make things slower. You can help form a hypothesis of how to make things better by doing an analysis. Data structure selection by far is the most important, and that's because choosing the right data structure can give dramatically better results over the wrong data structure. When dealing with performance issues. I tend to think in terms of 80% moves first. What are changes that could have an 80% reduction? And often the only thing that can get you that far are data structure changes. Once you've implemented them and measured the difference and still see it's not good enough, then you have to look at the smaller things. You might not know where to start, and that's where you'd want to look at the profiler. A profiler can tell you what are the hotspots of your code. It can point out functions that are the most expensive. There was kind of a funny story about Grand Theft Auto V online. It was so slow to launch that one player who goes by t0st wanted to figure out why. Even though they didn't have the source code t0st used a profiler figure out why it was so slow. It turned out pretty much all of the time was spent parsing and processing a JSON file. A patch to fix just that one part improved the load time by 70%. That's the funny thing with performance is that sometimes when things are slow, it's just one silly thing slowing everything down. For GTA V all someone had to do is look. After data structures and profiling then you just have to start making educated guesses, thinking about how your code could be working underneath the hood and find ways to simplify stuff. A lot of performance comes from how your code uses memory. Allocating memory, which is done whenever you make a new object or array, can slow things down in critical sections because the system has to find free chunks to put stuff. You'll get a lot of speed for having critical elements close by in memory because things are much, much faster when they're in the CPU's cache. But again, I wouldn't worry about these things until you know you have a performance problem and have tried other things first. So when you optimize: first, have a real performance problem, then measure it. Try to make 80% moves by swapping data structures or moving to a well-known faster algorithm. Profile and find hotspots. Then, worst case, start thinking about what your code is doing under the hood. What are some interesting cases you've hit while trying to make code faster? When a video of mine is getting long, I sometimes cut sections and post them as deleted scenes on my Patreon. For this video, we talked about micro optimization, but there's a section on my Patreon about macro optimization strategies. If you're curious.

# 07 Dependency Injection

Dependency injection is a term I don't love because it sounds a lot more fancy than it is. Dependency injection is simply when you have a piece of code which uses another piece of code, and instead of using that code directly, it's passed in instead. When you pass something in to be used, we call it injection. We inject the dependent code into the code that uses it. While this part is quite simple, it unlocks some very powerful side effects that we're going to cover. We have a business app where users can chat with their coworkers. They can also send pictures and files to each other. When a user sends something, the file gets uploaded to our attachment service. The attachment service is responsible for storing, retrieving and processing all attachments. We're going to build up this whole service using dependency injection and we'll see what it enables us to do. When a user sends a message with an attachment, the message text gets sent to our standard chat service. We want people to receive their messages almost real time. So this service is all about speed. The attachment, on the other hand, gets uploaded to our attachment service. There's an end point in our note service /attachment/upload that the app connects to and uploads a file. The attachment gets stored on the disk temporarily, processed in a few ways we'll talk about and then uploaded to its final destination. The default storage location is an S3, a part of Amazon's Web services. It's a simple storage service that lets you put up files and pull them down. We have some code here that takes the uploaded file and then uploads it to S3. Unfortunately, simple and elegant doesn't always like to co-exist with business. While S3 is nice and straightforward and most of our clients are okay with it, we have a few firms that don't want us to permanently store their data. This means we actually need our service to handle multiple storage locations. Then, depending on which company a user is from, we need to put their attachments in the right place. Most of these picky clients just give us an SFTP server to connect to, but one really wanted us to use WebDav. Our first thought might be to simply extend our upload code with some if statements and then have the caller of the upload method pass in where to upload the file. This is awkward for a few reasons. First, this one class has a ton of responsibility, making the code pretty ugly. The code for SFTP is intermingled with the code from AWS and WebDav, even though they're pretty different. There's a lot of paths the code can take, and that makes the code harder to understand. Second, using the class isn't very simple. We have this one upload function which needs a bunch of info for where we're going to upload the attachment. But what info it needs is very different depending on where it's going. If it's AWS, we need the AWS keys. If it's SFTP we need the address and private key and WebDav needs a URL and auth key. So we're kind of forced to have a bunch of these optional variables that need to be filled out in certain cases, and then comments to tell you which ones to fill out. This makes it pretty easy for the caller to make a mistake. And finally, the part of the code that actually calls upload over here needs to have all of this destination specific context to perform the upload. But really, at this phase, it just wants to upload. The part of the code that knows best which company a user is from and can deduce where the file should go is up here at the beginning of the request. But right now, we're forced to pass all of this information around. Let's see what happens if we use dependency injection instead. Let's create an interface that represents our attachment storage, which contains a key upload method that does what the request handler wants to do: Upload an attachment. Then we create three different implementations of the storage interface. The configuration for each is passed into their constructor. There's no more optional variables that sometimes need to be set. We require exactly these values and you get an error if you forget one. So now, once the user is authenticated and we know which company they're from, we create the storage that the request handler should use. Instead of the configuration needing to be passed all the way to the request handler, only the storage is passed to, or injected into, the request handler. It's not aware of which storage is passed in or where the file is going, it just knows that it can call upload. That said, this construction code is still a little too complex to put here, so let's see if we can clean this up. If we look at the input here, it's really just this company configuration and the output is the storage which conforms to the storage interface. So we can just move this out to a factory. Great. But saving to the final storage destination is the last step of the process. We have all these other stages that the upload goes through. We run each upload through a virus scanner. This checks the files for signatures of obvious viruses. Then if the file’s an image, we scale it down to a max width of 2500 pixels. This is what we display to the user when they click on an image because it uses less bandwidth and loads faster. Then the file goes through preview generation. This is basically the thumbnail that pops up underneath an attachment in the chat so the user can see what the attachment is without fully downloading it. Then the last step is encryption. If we're storing the files on Amazon's S3, we pre encrypt the files before sending them up. That way, if there's a security breach at Amazon, we can say they're encrypted when we have to send out one of those: ‘We were hacked, btw’, emails. So let's see how we can make each of these requirements fit cleanly into our service. For the virus scanner, we currently use a scanner called Threat Protect. However, Synergy Security Scanner has much better detection KPIs and our plan is to switch to it. But sadly, we haven't finalized the deal with Synergy We're only allowed to test with it in our development environment, not in production. No worries. We can create a shared interface for our two scanners and on initialization we pick one and inject that one into the request handler. When we launch in development mode, synergy security is initialized and in production the old Threat Protect scanner is created. Our request handler just scans the files but doesn't know which scanner is doing it. For image scaling, we use the sharp library in order to inject that, we simply wrap it up in an image scaler interface. The interface also contains a method which tells us if an attachment supports scaling. We injected into our upload, request and only scale if the attachment supports it. Preview generation is the most complex given how many types of attachments there could be. We have an interface that represents the different preview generators. It takes the input file and then returns the preview image. We have one implementation that handles document files like word docs, slides, etc. one for videos which extracts a thumbnail from the video and one for images. But the image one can thankfully just reuse our image scaler. We just inject the same image scaler from before into the image preview generator. So we have all these preview generator classes, but we only need one at a time depending on which file type is being uploaded. The upload request shouldn't need to worry about these details. We’ll inject a factory which takes on the burden of deciding which preview generator to create. The factory takes in the mime type of the upload and then returns the right preview generator to use. So now the upload can simply just ask the factory for the preview generator and then use it. And lastly, we have encryption. We only have one implementation of encryption. We use AES but the key is per user and comes from our key service. So we inject our KeyService into the AesEncryption and then the AesEncryption into the storage factory. Then whenever we get a request for a company that's configured to use AWS, the storage factory injects the AesEncryption into the new instance of AWSstorage. Then the upload request gets this final constructed AWSstorage and simply calls upload without knowing that there's this whole chain of connected functionality. And now we have our complete architecture. You can see that our service is configurable from this one spot, which makes it super easy to change. Once our deal with synergy security goes through, it's just these two lines to change our service. Want to add preview support for a new file type? It just slots in like this. No access to the key server when running the attachment service on your local development box? No worries. We can just use a fixed key when running locally. Injection basically just lets us pick and choose from our compatible puzzle pieces and then slot them in when we need them. You'll notice that the time in which dependencies are injected varies a bit. A few dependencies are resolved and injected right at startup,. This is often the most common scenario in dependency injection. But some dependencies that are chosen and injected when a request comes in. In either case, the process is mostly the same. We have some code that accomplishes something. It lists the dependencies it needs, and so we fulfill those needs. You might wonder why go through the hassle of creating interfaces and injecting things when we only have one implementation? Like we only have one implementation of encryption. Well, there's one big thing we haven't talked about. If you look at our architecture here, most of our components talk to each other through these interfaces, which are injected in. This means that each of these connection points we can control what is being used. We've been using this to choose which implementation to use in our production service, but we can also make them use no implementation. We can use injection to inject fake or mock implementations instead, which basically means we can slice and dice up our architecture to isolate sections of code during testing. Let's say we want to write a test for our AWS storage class. We can use a fake S3 which we run locally that pretends to be the cloud service. Then our test can call upload, and we can verify that a file got uploaded to S3. But because of the encryption, we can't actually check the content of the file and verify that it's correct and didn't get corrupted. Not to worry. Let's inject a mock encryption that basically just disables encryption. When the AWS storage class asks us to encrypt a file we'll just hand back a file that isn't actually encrypted. Now our test is able to verify fully that uploading and only uploading works because we've isolated it away from our dependencies. What if we wanted to test encryption? Well, we could mock out the key store to return a key that we control instead of going all the way to the key service. Or if we wanted to integration test both our AWS code and encryption code together. We could do that by injecting our fake key store into the real encryption and then inject the real encryption into the AWS storage. A key thing here is that this is easy to do. A natural side effect of having nice code is that it's easy to test without needing to hack around the code structure. If you find yourself asking, how can I test a private method? Or I need to set some internal variable in order to test. That's a signal that you maybe need to pull some stuff out, that you need to isolate some part of it by separating it and injecting it instead. I'm going to try something new with this video. I truly think you only learn stuff by trying stuff. So for those subscribed to my Patreon I'm going to start including some light experiments with videos. For this one, you can download the attachment service I wrote, and I want you to reconfigure the service by changing the dependency injection. And then you get to win some _Aesthetic_ points if you enter the results on the site.
